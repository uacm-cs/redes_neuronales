{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementar un MLP con PyTorch para clasificación basado en el dataset de agresividad\n",
    "# Uso de word embeddings como representación de datos\n",
    "\n",
    "\n",
    "<img src=\"figs/fig-diagrama-clasificador2.png\" width=\"900\">\n",
    "\n",
    "\n",
    "### 1. **Representar los datos en el modelo de word embeddings seleccionado**:  \n",
    "   - #### Generalmente, solo se tokeniza para separar adecuadamente las palabras.\n",
    "   - #### Sin embargo, dependiendo del modelos de word embeddings algunos preprocesamientos puede mejorar la representación.\n",
    "   - #### Por ejemplo: \n",
    "      - ##### tokenizar y separar correctamente las oraciones y palabras\n",
    "      - ##### convertir a minúsculas\n",
    "      - ##### quitar acentos (dependiendo de la fuente de datos con la que se generaros los embeddings)\n",
    "      - ##### quitar números y puntuación \n",
    "\n",
    "\n",
    "### 3. **Convertir los datos a vectores densos: word embeddings**:  \n",
    "   - #### En el caso de textos corto a nivel de oración, un vector denso por oración. \n",
    "\n",
    "### 4. **Separar los datos para entrenamiento, validación y prueba**:  \n",
    "   - #### Crear los dataset  con la función train_test_split \n",
    "   \n",
    "### 5. **Definir la arquitectura de la red**:  \n",
    "   - Definir una red de 2 capas, con funciones PReLU en las capas ocultas y una capa de salida\n",
    "\n",
    "### 6. **Entrenar el modelo**:  \n",
    "   - Definir los parámetros de las red como: número de épocas, learning_rate, número de neuronas para las capas ocultas, etc.\n",
    "   \n",
    "### 7. **Evaluar el modelo**:  \n",
    "   - Después del entrenamiento, probar la red con las entradas del conjunto de test y evaluar el desempeño con las métricas: Precisión, Recall, F1-score o F1-Measure y Accuracy.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import fasttext\n",
    "\n",
    "# colocar la semilla para la generación de números aleatorios para la reproducibilidad de experimentos\n",
    "\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "#cargar los datos\n",
    "dataset = pd.read_json(\"./data/data_aggressiveness_es.json\", lines=True)\n",
    "#conteo de clases\n",
    "print(\"Total de ejemplos de entrenamiento\")\n",
    "print(dataset.klass.value_counts())\n",
    "# Extracción de los textos en arreglos de numpy\n",
    "X = dataset['text'].to_numpy()\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y = dataset['klass'].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el modelo de Word Embeddings y crear los vectores densos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo de word embeddings\n",
    "ft = fasttext.load_model('/Users/uacm/UACM_local/datos/MX.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear los vectores densos para cada texto. Se espera una oración corta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción de los textos en arreglos de numpy\n",
    "# Se aplica una función lambda para obtener el vector de cada texto del conjunto de datos\n",
    "# El resultado es una nueva columna \"embedding\"\n",
    "dataset[\"embedding\"] = dataset[\"text\"].map(lambda x: ft.get_sentence_vector(x))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear la matriz de datos para el entrenamiento, validación y prueba del modelo de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cada renglón representa un documento codificado en un texto de embeddings\n",
    "X = np.vstack(dataset['embedding'].to_numpy())\n",
    "Y = dataset['klass'].to_numpy()\n",
    "\n",
    "print(\"Datos:\", X.shape) \n",
    "print(\"Etiquetas:\", Y.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Codificar las etiquetas de los datos a una forma categórica numérica: LabelEncoder.\n",
    "\n",
    "le = LabelEncoder()\n",
    "# Normalizar las etiquetas a una codificación ordinal para entrada del clasificador\n",
    "Y_encoded= le.fit_transform(Y)\n",
    "print(\"Clases:\")\n",
    "print(le.classes_)\n",
    "print(\"Clases codificadas:\")\n",
    "print(le.transform(le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar los conjuntos de datos  para el entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en conjunto de entrenamiento (80%) y conjunto de pruebas (20%)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test =  train_test_split(X, Y_encoded, test_size=0.2, stratify=Y_encoded, random_state=42)\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en:  entrenamiento (90%) y validación (10%)\n",
    "X_train, X_val, Y_train, Y_val =  train_test_split(X_train, Y_train, test_size=0.1, stratify=Y_train, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Codificar las clases en forma one-hot \n",
    "NUM_CLASSES = 2\n",
    "Y_train_one_hot = nn.functional.one_hot(torch.from_numpy(Y_train), num_classes=NUM_CLASSES).float()\n",
    "\n",
    "# Agregar dimensión de canales\n",
    "\n",
    "X_train = torch.tensor(X_train).unsqueeze(1)  # (3694, 1, 300)\n",
    "X_val = torch.tensor(X_val).unsqueeze(1)      # Similar para validación\n",
    "X_test = torch.tensor(X_test).unsqueeze(1)    # Similar para prueba\n",
    "\n",
    "\n",
    "# Crear minibatches en PyTorch usando DataLoader\n",
    "def create_minibatches(X, Y, batch_size):\n",
    "    # Recibe los documentos en X y las etiquetas en Y\n",
    "    dataset = TensorDataset(X, Y) # Cargar los datos en un dataset de tensores\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    # loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape, Y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_one_hot[:5],  Y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Conv1DTextClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        padding=1\n",
    "        kernel_size =3\n",
    "        stride = 1\n",
    "        dilation=1\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels=8, kernel_size=kernel_size, stride= stride, padding=padding, dilation=dilation)\n",
    "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=4, kernel_size=kernel_size, padding=padding, dilation=dilation)\n",
    "\n",
    "        L1 = ((300 + 2*padding - dilation * (kernel_size-1) -1 ) // stride ) + 1\n",
    "        L2 = ((L1 + 2*padding - dilation * (kernel_size-1) -1 ) // stride ) + 1\n",
    "\n",
    "        self.fc1 = nn.Linear(4 * L2, 8)  # Ajustar dimensiones según salida\n",
    "        self.fc2 = nn.Linear(8, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Aplanar\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = np.bincount(Y_train)  # Conteo de ejemplos por clase\n",
    "print(class_counts)\n",
    "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float32)\n",
    "class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Establecer los parámetros de la red\n",
    "\n",
    "# Parámetros de la red\n",
    "input_size =  X_train.shape[1]\n",
    "in_channels = 1\n",
    "output_size = 2   # 2 clases\n",
    "\n",
    "epochs = 10 # variar el número de épocas, para probar que funciona la programación \n",
    "                 # solo usar 2 épocas, para entrenamiento total usar por ejemplo 1000 épocas\n",
    "learning_rate = 0.001 # Generalmente se usan learning rate pequeños (0.001), \n",
    "\n",
    "# Se recomiendan tamaños de batch_size potencias de 2: 16, 32, 64, 128, 256\n",
    "# Entre mayor el número más cantidad de memoria se requiere para el procesamiento\n",
    "batch_size = 16 # definir el tamaño del lote de procesamiento \n",
    "\n",
    "\n",
    "# Convertir los datos de entrenamiento y etiquetas a tensores  de PyTorch\n",
    "\n",
    "# X_train_t = torch.from_numpy(X_train)\n",
    "# X_train_t = X_train_t.to(torch.float32)\n",
    "X_train_t = X_train\n",
    "Y_train_t = Y_train_one_hot\n",
    "\n",
    "# X_val_t = torch.from_numpy(X_val)\n",
    "# X_val_t = X_val_t.to(torch.float32)\n",
    "X_val_t = X_val\n",
    "\n",
    "\n",
    "# Crear la red\n",
    "model = Conv1DTextClassifier(in_channels, output_size)\n",
    "\n",
    "# Definir la función de pérdida\n",
    "# Entropía Cruzada \n",
    "class_counts = np.bincount(Y_train)  # Conteo de ejemplos por clase\n",
    "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float32)\n",
    "\n",
    "# class_weights ayuda a dar mayor peso a las clases desbalanceadas.\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "# Peso de las clases uniforme\n",
    "# criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Definir el optimizador\n",
    "#Parámetros del optimizador: parámetros del modelo y learning rate \n",
    "# Adaptive Moment Estimation\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Iniciando entrenamiento en PyTorch\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "# Poner el modelo en modo de entrenamiento\n",
    "    model.train()  \n",
    "    lossTotal = 0\n",
    "    #definir el batch_size\n",
    "    dataloader = create_minibatches(X_train_t, Y_train_t, batch_size=batch_size)\n",
    "    for X_tr, y_tr in dataloader:\n",
    "        # inicializar los gradientes en cero para cada época\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Propagación hacia adelante\n",
    "        y_pred = model(X_tr)  #invoca al método forward de la clase MLP\n",
    "        # Calcular el error MSE\n",
    "        loss = criterion(y_pred, y_tr)\n",
    "        #Acumular el error \n",
    "        lossTotal += loss.item()\n",
    "        \n",
    "        # Propagación hacia atrás: cálculo de los gradientes de los pesos y bias\n",
    "        loss.backward()\n",
    "        \n",
    "        # actualización de los pesos: regla de actualización basado en el gradiente:\n",
    "        #  \n",
    "        optimizer.step()\n",
    "        if np.random.random() < 0.1:\n",
    "            print(f\"Batch Error : {loss.item()}\")\n",
    "\n",
    "    print(f\"Época {epoch+1}/{epochs}, Pérdida: {lossTotal/len(dataloader)}\")\n",
    "    \n",
    "    # Evalúa el modelo con el conjunto de validación\n",
    "    model.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "    with torch.no_grad():  # No  calcular gradientes \n",
    "        y_pred = model(X_val_t)\n",
    "        # Obtiene una única clase, la más probable\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        print(f\"Época {epoch+1}/{epochs}\")\n",
    "        print(\"P=\", precision_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"R=\", recall_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"F1=\", f1_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"Acc=\", accuracy_score(Y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo para predicción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Transformar el dataset de test con los mismos preprocesamientos y al  espacio de \n",
    "# representación vectorial que el modelo entrenado, es decir, al espacio de la matriz TFIDF\n",
    "\n",
    "# Convertir los datos de prueba a tensores de PyTorch\n",
    "\n",
    "# X_t = torch.from_numpy(X_test)\n",
    "# X_t = X_t.to(torch.float32)\n",
    "X_t = X_test\n",
    "\n",
    "# Desactivar el comportamiento de modo de  entrenamiento: por ejemplo, capas como Dropout\n",
    "model.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "\n",
    "with torch.no_grad():  # No  calcular gradientes \n",
    "    y_pred_test= model(X_t)\n",
    "\n",
    "# y_test_pred contiene las predicciones\n",
    "\n",
    "# Obtener la clase real\n",
    "y_pred_test = torch.argmax(y_pred_test, dim=1)\n",
    "\n",
    "print(y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluar el modelo con las predicciones obtenidas y las etiquetas esperadas: \n",
    "# classification_report y  matriz de confusión (métricas Precisión, Recall, F1-measaure, Accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(confusion_matrix(Y_test, y_pred_test))\n",
    "print(classification_report(Y_test, y_pred_test, digits=4, zero_division='warn'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de datos nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_datos = [\"Esa hija de la se llevó mis cosas\", \"ese hijo de se llevo el dinero\", \"mi app de calendario no sirve\"]\n",
    "# Transformar los datos a vectores densos: word embeddings\n",
    "x_datos = [ft.get_sentence_vector(texto) for texto in x_datos]\n",
    "\n",
    "\n",
    "\n",
    "# Apilar los vectores verticalmente para tener un ejemplo.\n",
    "vectores = np.vstack(x_datos)\n",
    "\n",
    "vectores = torch.tensor(vectores).unsqueeze(1)      # Similar para validación\n",
    "print(vectores.shape)\n",
    "x_datos_t = vectores\n",
    "\n",
    "model.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "with torch.no_grad():  # No  calcular gradientes \n",
    "    y_pred = model(x_datos_t)\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "    print(le.inverse_transform(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modificar el número de neuronas de las capas lineales: capa1 y capa2 y evaluar si el modelo mejora o empeora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Aplicar una función lamba para que preprocese los textos con los siguientes características:\n",
    "#   - Tokenizar los datos para separar términos que estuvieran juntos por puntuación o símbolos extraños (sugerencia: usar word_tokenizer)\n",
    "#   - convertir a minúsculas\n",
    "#   - eliminar puntuación y símbolos duplicados\n",
    "# Comprobar si el rendimiento del modelo mejora o empeora.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
