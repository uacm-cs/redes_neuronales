{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementar un MLP con PyTorch para clasificación basado en el dataset de agresividad\n",
    "\n",
    "<img src=\"figs/fig-MLP_XOR.png\" width=\"50%\">\n",
    "\n",
    "\n",
    "1. **Definir los preprocesamientos para el texto**:  \n",
    "   - convertir a minúsculas\n",
    "   - normalizar el texto: borrar símbolos, puntuación, caracteres duplicados, etc.\n",
    "\n",
    "2. **Separar los datos para entrenamiento y prueba**:  \n",
    "   - Crear los dataset de entrenamiento y test con al función train_test_split \n",
    "\n",
    "3. **Construir la matriz de Documento-Término**:  \n",
    "   - Definir los parámetros para usar unigramas\n",
    "   - Usar la clase TfidfVectorizer para construir la matriz con los datos de entrenamiento\n",
    "\n",
    "   \n",
    "4. **Preparar los lotes de datos (minibatches) para el entrenamiento de la red**:  \n",
    "   - Definir los minibatches con la matriz TFIDF construida\n",
    "\n",
    "5. **Definir la arquitectura de la red**:  \n",
    "   - Definir entradas, salidas,  capas de la red y funciones de activación\n",
    "\n",
    "6. **Entrenar el modelo**:  \n",
    "   - Definir los parámetros de las red como: número de épocas, learning_rate, número de neuronas para las capas ocultas, etc.\n",
    "   \n",
    "7. **Evaluar el modelo**:  \n",
    "   - Después del entrenamiento, probar la red con las entradas del conjunto de test y evaluar el desempeño con las métricas: Precisión, Recall, F1-score o F1-Measure y Accuracy.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de los datos y minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# colocar la semilla para la generación de números aleatorios para la reproducibilidad de experimentos\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "\n",
    "# TODO: Cargar los datos de agresividad y separa los documentos (X) y las clases (Y)\n",
    "\n",
    "\n",
    "# TODO: Definir las funciones de preprocesamiento de texto vinculadas al proceso de creación de la matriz \n",
    "# Documeno-Término creada con TfidfVectorizer.\n",
    "\n",
    "\n",
    "# TODO: Codificar las etiquetas de los datos a una forma categórica numérica: LabelEncoder.\n",
    "\n",
    "\n",
    "# TODO: Dividir el conjunto de datos en conjunto de entrenamiento (80%) y conjunto de pruebas (20%)\n",
    "\n",
    "\n",
    "# TODO: Crear la matriz Documento-Término con el dataset de entrenamiento: tfidfVectorizer\n",
    "\n",
    "\n",
    "# Crear minibatches en PyTorch usando DataLoader\n",
    "def create_minibatches(X, Y, batch_size):\n",
    "    # Recibe los documentos en X y las etiquetas en Y\n",
    "    dataset = TensorDataset(X, Y) # Cargar los datos en un dataset de tensores\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la red neuronal en PyTorch heredando de la clase base de Redes Neuronales: Module\n",
    "class MLP(nn.Module):\n",
    "    # Definir los parámetros para la creación de la clase MLP\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        # TODO: Definición de capas, funciones de activación e inicialización de pesos\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Definición del orden de conexión de las capas y aplición de las funciones de activación\n",
    "        # TODO: DEFINIR EL ORDEN DE LAS CAPAS Y FUNCIONES DE ACTIVACIÓN\n",
    "        out = None\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer los parámetros de la red\n",
    "\n",
    "# Parámetros de la red\n",
    "input_size = 0 # --> ?\n",
    "hidden_size = 0 # --> ? \n",
    "output_size = 1  # La salida es el resultado de la sigmoide para un clasificador \n",
    "                 # binario: 0 o 1\n",
    "epochs = 100    # variar el número de épocas, para probar que funciona la programación \n",
    "                 # solo usar 2 épocas, para entrenamiento total usar por ejemplo 1000 épocas\n",
    "learning_rate = 0.2   # Generalmente se usan learning rate pequeños entre [0,1] como (0.1, 0.3), \n",
    "                      #\n",
    "\n",
    "# Se recomiendan tamaños de batch_size potencias de 2: 16, 32, 64, 128, 256\n",
    "# Entre mayor el número más cantidad de memoria se requiere para el procesamiento\n",
    "batch_size = 64 # definir el tamaño del lote de procesamiento \n",
    "\n",
    "\n",
    "# TODO: Convertir los datos de entrenamiento y etiquetas a tensores  de PyTorch\n",
    "\n",
    "X_train = [] # --> ?\n",
    "Y_train = [] # --> ?\n",
    "\n",
    "# Crear el modelo de la red \n",
    "# TODO: Ajustar los parámetros de acuerdo a su definición particular\n",
    "model = None # --> ?\n",
    "\n",
    "# TODO: Definir la función de pérdida\n",
    "# Mean Square Error (MSE)\n",
    "criterion = None # --> ?\n",
    "\n",
    "# Definir el optimizador\n",
    "# Parámetros del optimizador: parámetros del modelo y learning rate \n",
    "# Stochastic Gradient Descent (SGD)\n",
    "optimizer = None # --> ?\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Iniciando entrenamiento en PyTorch\")\n",
    "\n",
    "# Poner el modelo en modo de entrenamiento\n",
    "model.train()  \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lossTotal = 0\n",
    "    #definir el batch_size\n",
    "    dataloader = create_minibatches(X_train, Y_train, batch_size=batch_size)\n",
    "    for X_tr, y_tr in dataloader:\n",
    "        \n",
    "        # TODO: Inicializar los gradientes en cero para cada época\n",
    "        # --> ?\n",
    "        \n",
    "        # TODO: Propagación hacia adelante\n",
    "        # invoca al método forward de la clase MLP con los datos de entrenamiento\n",
    "        y_pred =  None # --> ?\n",
    "        \n",
    "        # Calcular el error MSE, de acuerdo a lo predicho (y_pred)  y la clase objetivo (y)\n",
    "        loss = None # --> ?\n",
    "        \n",
    "        # TODO: Acumular el error \n",
    "        lossTotal += loss.item()\n",
    "        \n",
    "        # TODO: Propagación hacia atrás: cálculo de los gradientes de los pesos y bias\n",
    "        # --> ?\n",
    "        \n",
    "        # TODO: Actualización de los pesos: regla de actualización basado en el gradiente:\n",
    "        # Regla delta:  W = W - learning_rate * dE/dW\n",
    "        # --> ?\n",
    "\n",
    "    print(f\"Época {epoch+1}/{epochs}, Pérdida: {lossTotal/len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo para predicción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Transformar el dataset de test con los mismos preprocesamientos y al  espacio de \n",
    "# representación vectorial que el modelo entrenado, es decir, al espacio de la matriz TFIDF\n",
    "\n",
    "# TODO: Convertir los datos de prueba a tensores de PyTorch\n",
    "X_test = None # --> ?\n",
    "Y_test = None # --> ?\n",
    "\n",
    "\n",
    "# TODO:  Desactivar el comportamiento de modo de  entrenamiento: por ejemplo, capas como Dropout\n",
    "# Establecer el modo del modelo a \"evaluación\"\n",
    "# --> ? \n",
    "\n",
    "with torch.no_grad():  # No  calcular gradientes \n",
    "    # TODO: Hacer la progragación hacia adelante para predecir los datos\n",
    "    \n",
    "    y_pred_test = None # --> ?\n",
    "\n",
    "    # y_test_pred contiene las predicciones numéricas de tipo float\n",
    "\n",
    "# TODO: Obtener la clase real: Clase biaria 0 o 1\n",
    "# --> ?\n",
    "y_pred_final = None # # --> ?\n",
    "\n",
    "print(y_pred_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluar el modelo con las predicciones obtenidas y las etiquetas esperadas: \n",
    "# classification_report y  matriz de confusión (métricas Precisión, Recall, F1-measaure, Accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
